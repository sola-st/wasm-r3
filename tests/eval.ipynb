{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "union:  43\n",
      "exclude:  8\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, subprocess\n",
    "\n",
    "\n",
    "def assert_cpus_disabled(start, end):\n",
    "    with open('/sys/devices/system/cpu/online', 'r') as f:\n",
    "        online_cpus = f.read().strip()\n",
    "        for cpu in range(start, end+1):\n",
    "            assert str(cpu) not in online_cpus, f\"CPU {cpu} is enabled\"\n",
    "def check_cpu_governor(start, end):\n",
    "    for cpu in range(start, end+1):\n",
    "        governor_file = f\"/sys/devices/system/cpu/cpu{cpu}/cpufreq/scaling_governor\"\n",
    "        if os.path.exists(governor_file):\n",
    "            with open(governor_file, 'r') as f:\n",
    "                governor = f.read().strip()\n",
    "                assert governor == 'performance', f\"CPU {cpu} governor is not set to performance\"\n",
    "        else:\n",
    "            print(f\"CPU {cpu} does not exist or does not have a scaling governor\")\n",
    "def assert_cover_all(expected_dirs):\n",
    "    online_tests_path = os.path.join(r3_path, 'tests/online')\n",
    "    actual_dirs = [name for name in os.listdir(online_tests_path) if os.path.isdir(os.path.join(online_tests_path, name))]\n",
    "    try:\n",
    "        assert set(actual_dirs) == set(expected_dirs)\n",
    "    except AssertionError:\n",
    "        missing_dirs = set(expected_dirs) - set(actual_dirs)\n",
    "        extra_dirs = set(actual_dirs) - set(expected_dirs)\n",
    "        print(f\"Assertion failed: Missing directories: {missing_dirs}, Extra directories: {extra_dirs}\")\n",
    "        raise\n",
    "def extract_samples_and_mean(output):\n",
    "    match = re.search(r\"recorded (\\d+) samples, mean = ([\\d\\.]+)\", output)\n",
    "    samples = int(match.group(1))\n",
    "    mean = float(match.group(2))\n",
    "    return [samples, mean]\n",
    "def extract_cycle_counts(output):\n",
    "    pattern = r\"(\\d+(?:,\\d+)*)\\s+cpu_core/cpu-cycles/\"\n",
    "    matches = re.findall(pattern, output)\n",
    "    cycle_counts = [int(match.replace(',', '')) for match in matches]\n",
    "    return cycle_counts\n",
    "def extract_summarize(output):\n",
    "    lines = output.strip().split('\\n')\n",
    "    data_line = lines[-1]\n",
    "    data_parts = data_line.split(',')\n",
    "    return [int(float(part)) for part in data_parts[1:]]\n",
    "def trace_match(metrics, testname):\n",
    "    return metrics[testname]['summary']['trace_match']\n",
    "\n",
    "test_input = \"\"\"\n",
    "DevTools listening on ws://127.0.0.1:9966/devtools/browser/f72191be-fbd6-4fbd-b21f-2703612f1f13\n",
    " Performance counter stats for 'CPU(s) 0-15':\n",
    "    40,125,664,880      cpu_core/cpu-cycles/                                                  \n",
    "       6.157604349 seconds time elapsed\n",
    " Performance counter stats for 'CPU(s) 0-15':\n",
    "     2,702,581,574      cpu_core/cpu-cycles/                                                  \n",
    "       0.267278301 seconds time elapsed\n",
    "\"\"\"\n",
    "assert extract_cycle_counts(test_input) == [40125664880, 2702581574]\n",
    "test_input_2 = \"\"\"\n",
    "================\n",
    "Run online tests\n",
    "================\n",
    "WARNING: You need a working internet connection\n",
    "WARNING: Tests depend on third party websites. If those websites changed since this testsuite was created, it might not work\n",
    "fib  -Histogram: V8.ExecuteMicroSeconds recorded 581 samples, mean = 9993.9 (flags = 0x41)\n",
    "\n",
    "581 9993.9\n",
    "nvm\n",
    "\"\"\"\n",
    "assert extract_samples_and_mean(test_input_2) == [581, 9993.9]\n",
    "test_input_3 = \"\"\"\n",
    "benchmark,instr:static_total,instr:static_replay,instrs:dynamic_total,instrs:dynamic_replay,ticks:total,ticks:replay\n",
    "/home/don/wasm-r3/tests/online/hydro/benchmark/bin_0/replay.wasm,344760,191,27138,59,228486,8934\n",
    "\"\"\"\n",
    "test_input_4 = \"\"\"\n",
    "benchmark,instr:static_total,instr:static_replay,instrs:dynamic_total,instrs:dynamic_replay,ticks:total,ticks:replay\n",
    "/home/don/wasm-r3/tests/online/multiplyDouble/benchmark/bin_0/replay.wasm,256244,238157,2.47543e+09,2100082177,9918500160,8.88911e+09\n",
    "\"\"\"\n",
    "assert(extract_summarize(test_input_3) == [344760, 191, 27138, 59, 228486, 8934])\n",
    "assert(extract_summarize(test_input_4) == [256244, 238157, 2475430000, 2100082177, 9918500160, 8889110000])\n",
    "\n",
    "# run ~/cpu.sh\n",
    "check_cpu_governor(0, 15)\n",
    "assert_cpus_disabled(16, 31)\n",
    "\n",
    "\n",
    "def get_replay_wasm(testname, opt):\n",
    "    regex = ''\n",
    "    match opt:\n",
    "        case 'noopt':\n",
    "            regex = 'merge|split|custom|benchmark'\n",
    "        case 'split':\n",
    "            regex = 'noopt|merge|custom|benchmark'\n",
    "        case 'merge':\n",
    "            regex = 'noopt|split|custom|benchmark'\n",
    "        case 'benchmark':\n",
    "            regex = 'noopt|split|merge|custom'\n",
    "        case _:\n",
    "            exit('invalid op')\n",
    "    find_command = f\"find {r3_path}/tests/online/{testname} -name replay.wasm | grep -vE '{regex}'\"\n",
    "    find_result = subprocess.run(find_command, shell=True, capture_output=True, text=True)\n",
    "    replay_path = find_result.stdout.strip()\n",
    "    return replay_path\n",
    "def get_pure_js(testname, opt):\n",
    "    regex = ''\n",
    "    match opt:\n",
    "        case 'noopt':\n",
    "            regex = 'merge|split|custom|benchmark'\n",
    "        case 'split':\n",
    "            regex = 'noopt|merge|custom|benchmark'\n",
    "        case 'merge':\n",
    "            regex = 'noopt|split|custom|benchmark'\n",
    "        case 'benchmark':\n",
    "            regex = 'noopt|split|merge|custom'\n",
    "        case _:\n",
    "            exit('invalid op')\n",
    "    find_command = f\"find {r3_path}/tests/online/{testname} -name pure.js | grep -vE '{regex}'\"\n",
    "    find_result = subprocess.run(find_command, shell=True, capture_output=True, text=True)\n",
    "    replay_path = find_result.stdout.strip()\n",
    "    return replay_path\n",
    "def get_glue_js(testname, opt):\n",
    "    regex = ''\n",
    "    match opt:\n",
    "        case 'noopt':\n",
    "            regex = 'merge|split|custom|benchmark'\n",
    "        case 'split':\n",
    "            regex = 'noopt|merge|custom|benchmark'\n",
    "        case 'merge':\n",
    "            regex = 'noopt|split|custom|benchmark'\n",
    "        case 'benchmark':\n",
    "            regex = 'noopt|split|merge|custom'\n",
    "        case _:\n",
    "            exit('invalid op')\n",
    "    find_command = f\"find {r3_path}/tests/online/{testname} -name replay.js | grep -vE '{regex}'\"\n",
    "    find_result = subprocess.run(find_command, shell=True, capture_output=True, text=True)\n",
    "    replay_path = find_result.stdout.strip()\n",
    "    return replay_path\n",
    "\n",
    "# Setup evaluation suite\n",
    "\n",
    "eval_set = ['fractals', 'parquet', 'ogv', 'factorial', 'gotemplate', 'sandspiel', 'hydro', 'hnset-bench', 'boa', 'livesplit', 'ffmpeg', 'takahirox', 'pathfinding', 'bullet', 'rustpython', 'timestretch', 'riconpacker', 'rguistyler', 'wheel', 'game-of-life', 'jsc', 'multiplyInt', 'fib', 'guiicons', 'funky-kart', 'playnox', 'jqkungfu', 'figma-startpage', 'sqlpractice', 'mandelbrot', 'pacalc', 'waforth', 'roslyn', 'lichess', 'rtexpacker', 'image-convolute', 'commanderkeen', 'onnxjs', 'rguilayout', 'rfxgen', 'rtexviewer', 'multiplyDouble', 'sqlgui']\n",
    "\n",
    "skip_set = [\n",
    "    'ogv' # record run is abnormal but not filtered out by test framework because it produces something.\n",
    "]\n",
    "\n",
    "# These are excluded as they don't appear in either Made with WebAssembly(https://madewithwebassembly.com/) or Awesome-Wasm(https://github.com/mbasso/awesome-wasm)\n",
    "excluded_set = [\n",
    "    \"handy-tools\",\n",
    "    'heatmap',\n",
    "    \"kittygame\",\n",
    "    'visual6502remix',\n",
    "    'noisereduction',\n",
    "    'skeletal',\n",
    "    'uarm',\n",
    "    'virtualkc',\n",
    "]\n",
    "\n",
    "print('union: ', len(eval_set))\n",
    "print('exclude: ', len(excluded_set))\n",
    "assert_cover_all(eval_set + excluded_set)\n",
    "\n",
    "testset = ['sqlpractice']\n",
    "metrics = {testname: { 'summary': {}, 'record_metrics': {}, 'replay_metrics': {}} for testname in testset }\n",
    "# with open('metrics.json', 'w') as f: json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isNormal: \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39margs)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [testname, isNormal]\n\u001b[0;32m---> 17\u001b[0m results \u001b[38;5;241m=\u001b[39m [\u001b[43mrun_wasmr3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m testname \u001b[38;5;129;01min\u001b[39;00m testset]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m testname, isNormal \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     19\u001b[0m     metrics[testname][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrace_match\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m isNormal\n",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m, in \u001b[0;36mrun_wasmr3\u001b[0;34m(testname)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m testname \u001b[38;5;129;01min\u001b[39;00m skip_set: \u001b[38;5;28;01mreturn\u001b[39;00m [testname, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[1;32m     11\u001b[0m command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. ~/.bashrc && timeout \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms npm test -- -t \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtestname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m isNormal \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m isNormal: \u001b[38;5;28mprint\u001b[39m(result\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1209\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/subprocess.py:2113\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2107\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2108\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2110\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2111\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2113\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2116\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.2/lib/python3.12/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess \n",
    "import json\n",
    "\n",
    "with open('metrics.json', 'r') as f: metrics = json.load(f)\n",
    "\n",
    "# Trace difference experiment\n",
    "timeout = 120\n",
    "\n",
    "def run_wasmr3(testname):\n",
    "    if testname in skip_set: return [testname, False]\n",
    "    command = f\". ~/.bashrc && timeout {timeout}s npm test -- -t {testname}\"\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    isNormal = result.returncode == 0\n",
    "    if not isNormal: print(result.args)\n",
    "    return [testname, isNormal]\n",
    "\n",
    "results = [run_wasmr3(testname) for testname in testset]\n",
    "for testname, isNormal in results:\n",
    "    metrics[testname]['summary']['trace_match'] = isNormal\n",
    "    if isNormal:\n",
    "        with open(f\"{r3_path}/tests/online/{testname}/benchmark/bin_0/stats.json\", 'r') as f: stats = json.load(f)\n",
    "        metrics[testname]['summary'] |= stats\n",
    "\n",
    "with open('metrics.json', 'w') as f: json.dump(metrics, f, indent=4)\n",
    "assert get_replay_wasm('game-of-life', 'benchmark') == f\"{r3_path}/tests/online/game-of-life/benchmark/bin_0/replay.wasm\"\n",
    "assert get_glue_js('game-of-life', 'benchmark') == f\"{r3_path}/tests/online/game-of-life/benchmark/bin_0/replay.js\"\n",
    "assert get_pure_js('game-of-life', 'benchmark') == f\"{r3_path}/tests/online/game-of-life/benchmark/bin_0/pure.js\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, csv, json\n",
    "\n",
    "with open('metrics.json', 'r') as f: metrics = json.load(f)\n",
    "\n",
    "# Replay characteristic experiment\n",
    "timeout = 180 # seconds\n",
    "wizard_engine_kind = ['wizeng-int']\n",
    "wizard_opt_kind = ['benchmark']\n",
    "\n",
    "# this lies as it actually collects from jit mode not int\n",
    "def run_icount(testname, engine, opt):\n",
    "    data_path = f\"/home/don/wasm-r3/tests/data/{testname}-icount.csv\"\n",
    "    replay_path = get_replay_wasm(testname, opt)\n",
    "    cmd = f'. ~/.bashrc && DATA_FILE={data_path} /home/don/wasm-r3-paper/oopsla/data/run-icount.bash {replay_path} wizeng.x86-64-linux'\n",
    "    try:        \n",
    "        result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, text=True)\n",
    "        with open(data_path, 'r') as f: \n",
    "            output = csv.DictReader(f)\n",
    "            output_dict = {row['Function']: {'static': row['static'], 'dynamic': row['dynamic']} for row in output}\n",
    "            return output_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run:\")\n",
    "        print(cmd)\n",
    "        return {}\n",
    "    \n",
    "def run_fprofile(testname, engine, opt):\n",
    "    data_path = f\"/home/don/wasm-r3/tests/data/{testname}-fprofile.csv\"\n",
    "    replay_path = get_replay_wasm(testname, opt)\n",
    "    cmd = f'. ~/.bashrc && DATA_FILE={data_path} /home/don/wasm-r3-paper/oopsla/data/run-fprofile.bash {replay_path} wizeng.x86-64-linux'\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, text=True)\n",
    "        with open(data_path, 'r') as f: \n",
    "            output = csv.DictReader(f)\n",
    "            output_dict = {}\n",
    "            summary_dict = {}\n",
    "            for row in output:\n",
    "                if row['Function'].startswith('r3'):\n",
    "                    output_dict[row['Function']] = {'count': row['count'], 'cycles': row['cycles'], 'percent': row['percent']}\n",
    "                else:\n",
    "                    key, value = row['Function'].rsplit(':', 1)\n",
    "                    summary_dict[key.strip()] = value.strip()\n",
    "            return output_dict, summary_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run:\")\n",
    "        print(cmd)\n",
    "        return {}, {}\n",
    "    \n",
    "def run_summarize(testname, engine, opt):\n",
    "    icount_path = f\"/home/don/wasm-r3/tests/data/{testname}-icount.csv\"\n",
    "    ticks_path = f\"/home/don/wasm-r3/tests/data/{testname}-fprofile.csv\"\n",
    "    replay_path = get_replay_wasm(testname, opt)\n",
    "    cmd = f'. ~/.bashrc && ICOUNT_FILE={icount_path} TICKS_FILE={ticks_path} /home/don/wasm-r3-paper/oopsla/data/summarize.bash {replay_path}'\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, text=True)\n",
    "        instr_static_total, instr_static_replay, instrs_dynamic_total, instr_dynamic_replay, ticks_total, ticks_replay = extract_summarize(result.stdout)\n",
    "        return {\n",
    "            'instr_static_total': instr_static_total,\n",
    "            'instr_static_replay': instr_static_replay,\n",
    "            'instrs_dynamic_total': instrs_dynamic_total,\n",
    "            'instr_dynamic_replay': instr_dynamic_replay,\n",
    "            'ticks_total': ticks_total,\n",
    "            'ticks_replay': ticks_replay,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run:\")\n",
    "        print(cmd)\n",
    "        return {}\n",
    "    \n",
    "results = []\n",
    "for testname in testset:\n",
    "    if trace_match(metrics, testname): \n",
    "        for engine in wizard_engine_kind:\n",
    "            for opt in wizard_opt_kind:\n",
    "                if not metrics[testname]['replay_metrics'].get(engine): metrics[testname]['replay_metrics'][engine] = {}\n",
    "                if not metrics[testname]['replay_metrics'][engine].get(opt): metrics[testname]['replay_metrics'][engine][opt] = {}\n",
    "                !mkdir -p data\n",
    "                metrics[testname]['replay_metrics'][engine][opt]['icount'] = run_icount(testname, engine, opt) \n",
    "                output_dict, summary_dict = run_fprofile(testname, engine, opt) \n",
    "                metrics[testname]['replay_metrics'][engine][opt]['fprofile'] = output_dict\n",
    "                metrics[testname]['summary'] |= {**run_summarize(testname, engine, opt)}\n",
    "\n",
    "with open('metrics.json', 'w') as f: json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n",
      "Failed to run funky-kart with noopt, engine: wizeng-int\n",
      ". ~/.bashrc && timeout 180s  wizeng.x86-64-linux --metrics /home/don/wasm-r3/tests/online/funky-kart/noopt/bin_0/replay.wasm\n"
     ]
    }
   ],
   "source": [
    "import subprocess, json, concurrent.futures, os\n",
    "\n",
    "with open('metrics.json', 'r') as f:  metrics = json.load(f)\n",
    "def trace_match(metrics, testname): return metrics[testname]['summary']['trace_match']\n",
    "timeout = 180 # seconds\n",
    "engine_kind = ['sm', 'sm-base', 'sm-opt', 'v8', 'v8-liftoff', 'v8-turbofan', 'jsc', 'jsc-int','jsc-bbq','jsc-omg', 'wizeng','wizeng-int','wizeng-jit','wizeng-dyn','wasmtime','wasmer','wasmer-base']\n",
    "opt_kind = ['noopt', 'split', 'merge', 'benchmark']\n",
    "\n",
    "r3_path = os.getenv('WASMR3_PATH', '/home/don/wasm-r3')\n",
    "\n",
    "def get_replay_wasm(testname, opt):\n",
    "    regex = ''\n",
    "    match opt:\n",
    "        case 'noopt':\n",
    "            regex = 'merge|split|custom|benchmark'\n",
    "        case 'split':\n",
    "            regex = 'noopt|merge|custom|benchmark'\n",
    "        case 'merge':\n",
    "            regex = 'noopt|split|custom|benchmark'\n",
    "        case 'benchmark':\n",
    "            regex = 'noopt|split|merge|custom'\n",
    "        case _:\n",
    "            exit('invalid op')\n",
    "    find_command = f\"find {r3_path}/tests/online/{testname} -name replay.wasm | grep -vE '{regex}'\"\n",
    "    find_result = subprocess.run(find_command, shell=True, capture_output=True, text=True)\n",
    "    replay_path = find_result.stdout.strip()\n",
    "    return replay_path\n",
    "\n",
    "def run_wizard(testname, engine, opt, i):\n",
    "    try: \n",
    "        replay_path = get_replay_wasm(testname, opt)\n",
    "        command = f\". ~/.bashrc && timeout {timeout}s  wizeng.x86-64-linux --metrics {replay_path}\"\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        if result.returncode != 0: raise Exception(result.args)\n",
    "        _, profile = result.stdout.split(\"pregen:time_us\")\n",
    "        profile = 'pregen:time_us' + profile\n",
    "        return [testname, engine, opt, i, {line.rsplit(\":\", 1)[0].strip(): line.rsplit(\":\", 1)[1].strip().replace(\"Î¼s\", \"\").strip() for line in profile.split(\"\\n\") if line}]\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run {testname} with {opt}, engine: {engine}\")\n",
    "        print(e)\n",
    "\n",
    "testset = metrics\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(run_wizard, testname, 'wizeng-int', opt, i) for testname in testset if trace_match(metrics, testname) for opt in opt_kind for i in range(10)]\n",
    "    results = [future.result() for future in concurrent.futures.as_completed(futures)]\n",
    "\n",
    "for result in results:\n",
    "    if result is None: continue\n",
    "    testname, engine, opt, i, metric = result\n",
    "    try: \n",
    "        if not metrics[testname]['replay_metrics'][engine]: metrics[testname]['replay_metrics'][engine] = {}\n",
    "        if not isinstance(metrics[testname]['replay_metrics'][engine][opt], list): metrics[testname]['replay_metrics'][engine][opt] = []\n",
    "        metrics[testname]['replay_metrics'][engine][opt].append(metric)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to store {testname} with {opt}, engine: {engine}\")\n",
    "        print(e)\n",
    "with open('metrics.json', 'w') as f: json.dump(metrics, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
